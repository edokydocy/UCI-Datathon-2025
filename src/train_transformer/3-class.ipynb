{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3-class classification solution\n",
    "\n",
    "Start with prepare the dataset:"
   ],
   "id": "411fa5749d1019d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:33:44.599700Z",
     "start_time": "2025-04-13T11:33:41.899038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cProfile import label\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/processed_data.csv\")\n",
    "\n",
    "def get_value(row: \"a row of dataframe\"):\n",
    "    if row['winner_model_a'] == 1:\n",
    "        return 0\n",
    "    elif row['winner_model_b'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df[\"label\"] = df.apply(get_value, axis = 1)     # axis=1: apply to every ROW\n",
    "\n",
    "def gen_input(row):\n",
    "    return f\"[PROMPT] {row['clean_prompt']} [RESPONSE_A] {row['clean_response_a']} [RESPONSE_B] {row['clean_response_b']}\"\n",
    "\n",
    "df[\"input\"] = df.apply(gen_input, axis=1)\n",
    "df[[\"label\",\"input\"]]"
   ],
   "id": "b5ec4891b61ce1b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       label                                              input\n",
       "0          0  [PROMPT] is it morally right to try to have a ...\n",
       "1          1  [PROMPT] what is the difference between marria...\n",
       "2          2  [PROMPT] explain function calling. how would y...\n",
       "3          0  [PROMPT] how can i create a test set for a ver...\n",
       "4          1  [PROMPT] what is the best way to travel from t...\n",
       "...      ...                                                ...\n",
       "57472      0  [PROMPT] a simple mnemonic for π how i wish i ...\n",
       "57473      0  [PROMPT] in python, implement a naive bayes wi...\n",
       "57474      0  [PROMPT] is it unethical to work on building w...\n",
       "57475      1  [PROMPT] if a bait contains 0, 0025 bromadiolo...\n",
       "57476      0  [PROMPT] three kids eat three apples in three ...\n",
       "\n",
       "[57477 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[PROMPT] is it morally right to try to have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[PROMPT] what is the difference between marria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[PROMPT] explain function calling. how would y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[PROMPT] how can i create a test set for a ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[PROMPT] what is the best way to travel from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>0</td>\n",
       "      <td>[PROMPT] a simple mnemonic for π how i wish i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>0</td>\n",
       "      <td>[PROMPT] in python, implement a naive bayes wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>0</td>\n",
       "      <td>[PROMPT] is it unethical to work on building w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>1</td>\n",
       "      <td>[PROMPT] if a bait contains 0, 0025 bromadiolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>0</td>\n",
       "      <td>[PROMPT] three kids eat three apples in three ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Then we apply the model from transformer.\n",
    "\n",
    "First, we tokenize our input information, which means making them into numbers that BERT can understand."
   ],
   "id": "174e5d5d165eb405"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:38:16.736099Z",
     "start_time": "2025-04-13T11:33:44.630702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tknzr = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenize\n",
    "encodings = tknzr(\n",
    "    df[\"input\"].tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\" # pytorch tensors\n",
    ")"
   ],
   "id": "24444d7872f161a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\UCI-Datathon-2025\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Second, we create dataset object for pytorch:",
   "id": "2ed0e7ef9617a034"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:38:16.905092Z",
     "start_time": "2025-04-13T11:38:16.891093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LLMPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings  # input_ids and attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        item = {key: val[i] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[i])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "dst = LLMPDataset(encodings, df['label'].tolist())"
   ],
   "id": "5297fc52b3556e38",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load a pre-trained model:",
   "id": "73034e885afc9c48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:38:17.269100Z",
     "start_time": "2025-04-13T11:38:16.911092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# use the model with 3-output labels\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 3)"
   ],
   "id": "bf052747533faef8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set trainning arguments:",
   "id": "600f5325b234cbd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:38:17.299099Z",
     "start_time": "2025-04-13T11:38:17.285093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)"
   ],
   "id": "94a6eb9bfce710d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26.0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:43:46.872024Z",
     "start_time": "2025-04-13T11:43:46.863094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "import accelerate\n",
    "\n",
    "train_arg = TrainingArguments(\n",
    "    output_dir=\"./train_result\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    fp16=True,  # Mixed precision for speed\n",
    ")"
   ],
   "id": "3231a4e2a1f78a3b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then, train the model:",
   "id": "d1d8f17678586255"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T11:43:49.343631Z",
     "start_time": "2025-04-13T11:43:49.337634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # should return True\n",
    "print(torch.cuda.get_device_name(0))  # prints your GPU name if available"
   ],
   "id": "e1591952444347a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T12:35:35.865443Z",
     "start_time": "2025-04-13T11:43:53.130928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args= train_arg,\n",
    "    train_dataset= dst,\n",
    "    eval_dataset= dst\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "e165b91ade12088f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\UCI-Datathon-2025\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:449: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7186' max='7186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7186/7186 51:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.100600</td>\n",
       "      <td>1.097652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.093500</td>\n",
       "      <td>1.092521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7186, training_loss=1.0975880366728028, metrics={'train_runtime': 3102.5845, 'train_samples_per_second': 37.051, 'train_steps_per_second': 2.316, 'total_flos': 3.024593982150451e+16, 'train_loss': 1.0975880366728028, 'epoch': 2.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate the result:",
   "id": "90f4dde92fbde582"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T12:41:07.251053Z",
     "start_time": "2025-04-13T12:36:03.351514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ],
   "id": "dae6bbca0a25b96c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0925211906433105, 'eval_runtime': 303.8905, 'eval_samples_per_second': 189.137, 'eval_steps_per_second': 11.823, 'epoch': 2.0}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T12:56:56.050740Z",
     "start_time": "2025-04-13T12:51:46.369842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_output = trainer.predict(dst)\n",
    "\n",
    "logits = pred_output.predictions\n",
    "preds = np.argmax(logits, axis=1)\n",
    "labels = pred_output.label_ids\n",
    "\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "print(\"Accuracy on full dataset:\", accuracy)"
   ],
   "id": "6ce4f1a33c65c5b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on full dataset: 0.36357151556274686\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
